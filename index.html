<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Web Experimental SLAM v3 Fixed</title>

<script src="https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.min.js"></script>
<script src="https://docs.opencv.org/4.8.0/opencv.js"></script>

<style>
body { margin:0; overflow:hidden; }
video { display:none; }
canvas { position:absolute; top:0; left:0; }
</style>
</head>
<body>

<video id="video" autoplay playsinline></video>
<canvas id="three"></canvas>
<canvas id="cv" style="display:none;"></canvas>

<script>

let video = document.getElementById("video");
let threeCanvas = document.getElementById("three");
let cvCanvas = document.getElementById("cv");

let scene, camera, renderer, cube;

let prevGray = null;
let prevKeypoints = null;
let prevDescriptors = null;

let globalMatrix = new THREE.Matrix4();

// เปิดกล้อง
navigator.mediaDevices.getUserMedia({
  video: { facingMode: "environment" }
}).then(stream => {
  video.srcObject = stream;
  video.play();
});

// THREE INIT
function initThree(){

  renderer = new THREE.WebGLRenderer({canvas:threeCanvas, alpha:true});
  renderer.setSize(window.innerWidth, window.innerHeight);

  scene = new THREE.Scene();

  camera = new THREE.PerspectiveCamera(
    60,
    window.innerWidth/window.innerHeight,
    0.01,
    1000
  );

  camera.position.set(0,0,0);

  const geometry = new THREE.BoxGeometry(0.5,0.5,0.5);
  const material = new THREE.MeshNormalMaterial();
  cube = new THREE.Mesh(geometry,material);
  cube.position.set(0,0,-3);

  scene.add(cube);

  animate();
}

function animate(){
  requestAnimationFrame(animate);
  renderer.render(scene,camera);
}

function processFrame(){

  if (!video.videoWidth){
    requestAnimationFrame(processFrame);
    return;
  }

  cvCanvas.width = video.videoWidth;
  cvCanvas.height = video.videoHeight;

  let ctx = cvCanvas.getContext("2d",{willReadFrequently:true});
  ctx.drawImage(video,0,0);

  let src = cv.imread(cvCanvas);
  let gray = new cv.Mat();
  cv.cvtColor(src,gray,cv.COLOR_RGBA2GRAY);

  let orb = new cv.ORB();
  let keypoints = new cv.KeyPointVector();
  let descriptors = new cv.Mat();

  orb.detectAndCompute(gray,new cv.Mat(),keypoints,descriptors);

  if (prevDescriptors && descriptors.rows > 20){

    let bf = new cv.BFMatcher(cv.NORM_HAMMING,true);
    let matches = new cv.DMatchVector();
    bf.match(prevDescriptors,descriptors,matches);

    if (matches.size() > 30){

      let pts1 = [];
      let pts2 = [];

      for(let i=0;i<matches.size();i++){
        let m = matches.get(i);
        let kp1 = prevKeypoints.get(m.queryIdx);
        let kp2 = keypoints.get(m.trainIdx);
        pts1.push(kp1.pt.x, kp1.pt.y);
        pts2.push(kp2.pt.x, kp2.pt.y);
      }

      let mat1 = cv.matFromArray(pts1.length/2,2,cv.CV_32F,pts1);
      let mat2 = cv.matFromArray(pts2.length/2,2,cv.CV_32F,pts2);

      let focal = 800;

      // ✅ FIX: ไม่ใช้ cv.Point2f แล้ว
      let E = cv.findEssentialMat(
        mat1,
        mat2,
        focal,
        gray.cols/2,
        gray.rows/2,
        cv.RANSAC,
        0.999,
        1.0
      );

      if (E && !E.empty()){

        let R = new cv.Mat();
        let t = new cv.Mat();
        let mask = new cv.Mat();

        cv.recoverPose(
          E,
          mat1,
          mat2,
          R,
          t,
          focal,
          gray.cols/2,
          gray.rows/2,
          mask
        );

        // แปลง R เป็น Three.js matrix
        let rot = new THREE.Matrix4().set(
          R.doubleAt(0,0),R.doubleAt(0,1),R.doubleAt(0,2),0,
          R.doubleAt(1,0),R.doubleAt(1,1),R.doubleAt(1,2),0,
          R.doubleAt(2,0),R.doubleAt(2,1),R.doubleAt(2,2),0,
          0,0,0,1
        );

        let scaleFactor = 0.1; // ปรับ scale motion
        let trans = new THREE.Matrix4().makeTranslation(
          t.doubleAt(0,0)*scaleFactor,
          t.doubleAt(1,0)*scaleFactor,
          t.doubleAt(2,0)*scaleFactor
        );

        let delta = new THREE.Matrix4();
        delta.multiplyMatrices(trans,rot);

        globalMatrix.multiply(delta);

        camera.matrix.copy(globalMatrix);
        camera.matrix.decompose(
          camera.position,
          camera.quaternion,
          camera.scale
        );

        R.delete();
        t.delete();
        mask.delete();
      }

      mat1.delete();
      mat2.delete();
      E.delete();
    }

    matches.delete();
  }

  if (prevGray){
    prevGray.delete();
    prevKeypoints.delete();
    prevDescriptors.delete();
  }

  prevGray = gray.clone();
  prevKeypoints = keypoints;
  prevDescriptors = descriptors.clone();

  src.delete();

  requestAnimationFrame(processFrame);
}

function waitForOpenCV(){
  if (typeof cv === "undefined" || !cv.Mat){
    requestAnimationFrame(waitForOpenCV);
  } else {
    initThree();
    processFrame();
  }
}

waitForOpenCV();


</script>
</body>
</html>
